{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Off-Platform Project: Classifying Tweets\n",
    "\n",
    "In this off-platform project, you will use a Naive Bayes Classifier to find patterns in real tweets. We've given you three files: `new_york.json`, `london.json`, and `paris.json`. These three files contain tweets that we gathered from those locations.\n",
    "\n",
    "The goal is to create a classification algorithm that can classify any tweet (or sentence) and predict whether that sentence came from New York, London, or Paris."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Investigate the Data\n",
    "\n",
    "To begin, let's take a look at the data. We've imported `new_york.json` and printed the following information:\n",
    "* The number of tweets.\n",
    "* The columns, or features, of a tweet.\n",
    "* The text of the 12th tweet in the New York dataset.\n",
    "\n",
    "Run the cell below to see the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "new_york_tweets = pd.read_json(\"new_york.json\", lines=True)\r\n",
    "print(len(new_york_tweets))\r\n",
    "print(new_york_tweets.columns)\r\n",
    "print(new_york_tweets.loc[12][\"text\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4723\n",
      "Index(['created_at', 'id', 'id_str', 'text', 'display_text_range', 'source',\n",
      "       'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
      "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
      "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
      "       'contributors', 'is_quote_status', 'quote_count', 'reply_count',\n",
      "       'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted',\n",
      "       'filter_level', 'lang', 'timestamp_ms', 'extended_tweet',\n",
      "       'possibly_sensitive', 'quoted_status_id', 'quoted_status_id_str',\n",
      "       'quoted_status', 'quoted_status_permalink', 'extended_entities',\n",
      "       'withheld_in_countries'],\n",
      "      dtype='object')\n",
      "Be best #ThursdayThoughts\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "pd.set_option('display.max_columns', None)\r\n",
    "new_york_tweets.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 created_at                   id               id_str  \\\n",
       "0 2018-07-26 13:32:33+00:00  1022474755625164800  1022474755625164800   \n",
       "1 2018-07-26 13:32:34+00:00  1022474762491183104  1022474762491183104   \n",
       "2 2018-07-26 13:32:35+00:00  1022474765750226945  1022474765750226944   \n",
       "3 2018-07-26 13:32:36+00:00  1022474768736546816  1022474768736546816   \n",
       "4 2018-07-26 13:32:36+00:00  1022474769260838913  1022474769260838912   \n",
       "\n",
       "                                                text display_text_range  \\\n",
       "0                   @DelgadoforNY19 Calendar marked.           [16, 32]   \n",
       "1    petition to ban more than one spritz of cologne                NaN   \n",
       "2  People really be making up beef with you in th...                NaN   \n",
       "3  30 years old.. wow what a journey... I moved t...                NaN   \n",
       "4  At first glance it looked like asparagus with ...                NaN   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "3  <a href=\"http://instagram.com\" rel=\"nofollow\">...       True   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...       True   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0           1.022208e+18               1.022208e+18         8.290618e+17   \n",
       "1                    NaN                        NaN                  NaN   \n",
       "2                    NaN                        NaN                  NaN   \n",
       "3                    NaN                        NaN                  NaN   \n",
       "4                    NaN                        NaN                  NaN   \n",
       "\n",
       "   in_reply_to_user_id_str in_reply_to_screen_name  \\\n",
       "0             8.290618e+17          DelgadoforNY19   \n",
       "1                      NaN                    None   \n",
       "2                      NaN                    None   \n",
       "3                      NaN                    None   \n",
       "4                      NaN                    None   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'id': 316616881, 'id_str': '316616881', 'name...   \n",
       "1  {'id': 23692064, 'id_str': '23692064', 'name':...   \n",
       "2  {'id': 219516383, 'id_str': '219516383', 'name...   \n",
       "3  {'id': 294201642, 'id_str': '294201642', 'name...   \n",
       "4  {'id': 455408518, 'id_str': '455408518', 'name...   \n",
       "\n",
       "                                                 geo  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  {'type': 'Point', 'coordinates': [40.76074541,...   \n",
       "4                                               None   \n",
       "\n",
       "                                         coordinates  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  {'type': 'Point', 'coordinates': [-73.99905224...   \n",
       "4                                               None   \n",
       "\n",
       "                                               place  contributors  \\\n",
       "0  {'id': '01a9a39529b27f36', 'url': 'https://api...           NaN   \n",
       "1  {'id': '01a9a39529b27f36', 'url': 'https://api...           NaN   \n",
       "2  {'id': '8479859139338fb7', 'url': 'https://api...           NaN   \n",
       "3  {'id': '01a9a39529b27f36', 'url': 'https://api...           NaN   \n",
       "4  {'id': '01a9a39529b27f36', 'url': 'https://api...           NaN   \n",
       "\n",
       "   is_quote_status  quote_count  reply_count  retweet_count  favorite_count  \\\n",
       "0            False            0            0              0               0   \n",
       "1            False            0            0              0               0   \n",
       "2            False            0            0              0               0   \n",
       "3            False            0            0              0               0   \n",
       "4            False            0            0              0               0   \n",
       "\n",
       "                                            entities  favorited  retweeted  \\\n",
       "0  {'hashtags': [], 'urls': [], 'user_mentions': ...      False      False   \n",
       "1  {'hashtags': [], 'urls': [], 'user_mentions': ...      False      False   \n",
       "2  {'hashtags': [], 'urls': [], 'user_mentions': ...      False      False   \n",
       "3  {'hashtags': [], 'urls': [{'url': 'https://t.c...      False      False   \n",
       "4  {'hashtags': [], 'urls': [{'url': 'https://t.c...      False      False   \n",
       "\n",
       "  filter_level lang            timestamp_ms  \\\n",
       "0          low   en 2018-07-26 13:32:33.060   \n",
       "1          low   en 2018-07-26 13:32:34.697   \n",
       "2          low   en 2018-07-26 13:32:35.474   \n",
       "3          low   en 2018-07-26 13:32:36.186   \n",
       "4          low   en 2018-07-26 13:32:36.311   \n",
       "\n",
       "                                      extended_tweet  possibly_sensitive  \\\n",
       "0                                                NaN                 NaN   \n",
       "1                                                NaN                 NaN   \n",
       "2                                                NaN                 NaN   \n",
       "3  {'full_text': '30 years old.. wow what a journ...                 0.0   \n",
       "4  {'full_text': 'At first glance it looked like ...                 NaN   \n",
       "\n",
       "   quoted_status_id  quoted_status_id_str quoted_status  \\\n",
       "0               NaN                   NaN           NaN   \n",
       "1               NaN                   NaN           NaN   \n",
       "2               NaN                   NaN           NaN   \n",
       "3               NaN                   NaN           NaN   \n",
       "4               NaN                   NaN           NaN   \n",
       "\n",
       "  quoted_status_permalink extended_entities withheld_in_countries  \n",
       "0                     NaN               NaN                   NaN  \n",
       "1                     NaN               NaN                   NaN  \n",
       "2                     NaN               NaN                   NaN  \n",
       "3                     NaN               NaN                   NaN  \n",
       "4                     NaN               NaN                   NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>user</th>\n",
       "      <th>geo</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>contributors</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>entities</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-26 13:32:33+00:00</td>\n",
       "      <td>1022474755625164800</td>\n",
       "      <td>1022474755625164800</td>\n",
       "      <td>@DelgadoforNY19 Calendar marked.</td>\n",
       "      <td>[16, 32]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.022208e+18</td>\n",
       "      <td>1.022208e+18</td>\n",
       "      <td>8.290618e+17</td>\n",
       "      <td>8.290618e+17</td>\n",
       "      <td>DelgadoforNY19</td>\n",
       "      <td>{'id': 316616881, 'id_str': '316616881', 'name...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': '01a9a39529b27f36', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:33.060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-26 13:32:34+00:00</td>\n",
       "      <td>1022474762491183104</td>\n",
       "      <td>1022474762491183104</td>\n",
       "      <td>petition to ban more than one spritz of cologne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 23692064, 'id_str': '23692064', 'name':...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': '01a9a39529b27f36', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:34.697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-26 13:32:35+00:00</td>\n",
       "      <td>1022474765750226945</td>\n",
       "      <td>1022474765750226944</td>\n",
       "      <td>People really be making up beef with you in th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 219516383, 'id_str': '219516383', 'name...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': '8479859139338fb7', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:35.474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-26 13:32:36+00:00</td>\n",
       "      <td>1022474768736546816</td>\n",
       "      <td>1022474768736546816</td>\n",
       "      <td>30 years old.. wow what a journey... I moved t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 294201642, 'id_str': '294201642', 'name...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [40.76074541,...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-73.99905224...</td>\n",
       "      <td>{'id': '01a9a39529b27f36', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:36.186</td>\n",
       "      <td>{'full_text': '30 years old.. wow what a journ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-26 13:32:36+00:00</td>\n",
       "      <td>1022474769260838913</td>\n",
       "      <td>1022474769260838912</td>\n",
       "      <td>At first glance it looked like asparagus with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 455408518, 'id_str': '455408518', 'name...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': '01a9a39529b27f36', 'url': 'https://api...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:36.311</td>\n",
       "      <td>{'full_text': 'At first glance it looked like ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the code block below, load the London and Paris tweets into DataFrames named `london_tweets` and `paris_tweets`.\n",
    "\n",
    "How many London tweets are there? How many Paris ones are there?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "london_tweets = pd.read_json(\"london.json\", lines=True)\r\n",
    "paris_tweets = pd.read_json(\"paris.json\", lines=True)\r\n",
    "\r\n",
    "print('length london: '+ str(len(london_tweets)))\r\n",
    "print('paris length: '+ str(len(paris_tweets)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "length london: 5341\n",
      "paris length: 2510\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classifying using language: Naive Bayes Classifier\n",
    "\n",
    "We're going to create a Naive Bayes Classifier! Let's begin by looking at the way language is used differently in these three locations. Let's grab the text of all of the tweets and make it one big list. In the code block below, we've created a list of all the New York tweets. Do the same for `london_tweets` and `paris_tweets`.\n",
    "\n",
    "Then combine all three into a variable named `all_tweets` by using the `+` operator. For example, `all_tweets = new_york_text + london_text + ...`\n",
    "\n",
    "Let's also make the labels associated with those tweets. `0` represents a New York tweet, `1`  represents a London tweet, and `2` represents a Paris tweet. Finish the definition of `labels`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "new_york_text = new_york_tweets[\"text\"].tolist()\r\n",
    "london_text = london_tweets['text'].tolist()\r\n",
    "paris_text = paris_tweets['text'].tolist()\r\n",
    "\r\n",
    "all_tweets = new_york_text + london_text + paris_text\r\n",
    "labels = [0] * len(new_york_text) + [1] * len(london_text) + [2] * len(paris_text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making a Training and Test Set\n",
    "\n",
    "We can now break our data into a training set and a test set. We'll use scikit-learn's `train_test_split` function to do this split. This function takes two required parameters: It takes the data, followed by the labels. Set the optional parameter `test_size` to be `0.2`. Finally, set the optional parameter `random_state` to `1`. This will make it so your data is split in the same way as the data in our solution code. \n",
    "\n",
    "Remember, this function returns 4 items in this order:\n",
    "1. The training data\n",
    "2. The testing data\n",
    "3. The training labels\n",
    "4. The testing labels\n",
    "\n",
    "Store the results in variables named `train_data`, `test_data`, `train_labels`, and `test_labels`.\n",
    "\n",
    "Print the length of `train_data` and the length of `test_data`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(all_tweets,labels, test_size=0.2,random_state=1)\r\n",
    "print(len(train_data))\r\n",
    "print(len(test_data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10059\n",
      "2515\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making the Count Vectors\r\n",
    "\r\n",
    "To use a Naive Bayes Classifier, we need to transform our lists of words into count vectors. Recall that this changes the sentence `\"I love New York, New York\"` into a list that contains:\r\n",
    "\r\n",
    "* Two `1`s because the words `\"I\"` and `\"love\"` each appear once.\r\n",
    "* Two `2`s because the words `\"New\"` and `\"York\"` each appear twice.\r\n",
    "* Many `0`s because every other word in the training set didn't appear at all.\r\n",
    "\r\n",
    "To start, create a `CountVectorizer` named `counter`.\r\n",
    "\r\n",
    "Next, call the `.fit()` method using `train_data` as a parameter. This teaches the counter our vocabulary.\r\n",
    "\r\n",
    "Finally, let's transform `train_data` and `test_data` into Count Vectors. Call `counter`'s `.transform()` method using `train_data` as a parameter and store the result in `train_counts`. Do the same for `test_data` and store the result in `test_counts`.\r\n",
    "\r\n",
    "Print `train_data[3]` and `train_counts[3]` to see what a tweet looks like as a Count Vector."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "counter = CountVectorizer()\r\n",
    "counter.fit(train_data)\r\n",
    "train_counts = counter.transform(train_data)\r\n",
    "test_counts = counter.transform(test_data)\r\n",
    "\r\n",
    "print('train_data ' + str(train_data[3]))\r\n",
    "print(train_counts[3])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_data saying bye is hard. Especially when youre saying bye to comfort.\n",
      "  (0, 5022)\t2\n",
      "  (0, 6371)\t1\n",
      "  (0, 9552)\t1\n",
      "  (0, 12314)\t1\n",
      "  (0, 13903)\t1\n",
      "  (0, 23994)\t2\n",
      "  (0, 27146)\t1\n",
      "  (0, 29397)\t1\n",
      "  (0, 30274)\t1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and Test the Naive Bayes Classifier\n",
    "\n",
    "We now have the inputs to our classifier. Let's use the CountVectors to train and test the Naive Bayes Classifier!\n",
    "\n",
    "First, make a `MultinomialNB` named `classifier`.\n",
    "\n",
    "Next, call `classifier`'s `.fit()` method. This method takes two parameters &mdash; the training data and the training labels. `train_counts` contains the training data and `train_labels` containts the labels for that data.\n",
    "\n",
    "Calling `.fit()` calculates all of the probabilities used in Bayes Theorem. The model is now ready to quickly predict the location of a new tweet. \n",
    "\n",
    "Finally, let's test our model. `classifier`'s `.predict()` method using `test_counts` as a parameter. Store the results in a variable named `predictions`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "classifier = MultinomialNB()\r\n",
    "classifier.fit(train_counts,train_labels)\r\n",
    "predictions = classifier.predict(test_counts)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating Your Model\n",
    "\n",
    "Now that the classifier has made its predictions, let's see how well it did. Let's look at two different ways to do this. First, call scikit-learn's `accuracy_score` function. This function should take two parameters &mdash;  the `test_labels` and your `predictions`. Print the results. This prints the percentage of tweets in the test set that the classifier correctly classified.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "print(accuracy_score(test_labels,predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6779324055666004\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The other way you can evaluate your model is by looking at the **confusion matrix**. A confusion matrix is a table that describes how your classifier made its predictions. For example, if there were two labels, A and B, a confusion matrix might look like this:\n",
    "\n",
    "```\n",
    "9 1\n",
    "3 5\n",
    "```\n",
    "\n",
    "In this example, the first row shows how the classifier classified the true A's. It guessed that 9 of them were A's and 1 of them was a B. The second row shows how the classifier did on the true B's. It guessed that 3 of them were A's and 5 of them were B's.\n",
    "\n",
    "For our project using tweets, there were three classes &mdash; `0` for New York, `1` for London, and `2` for Paris. You can see the confustion matrix by printing the result of the `confusion_matrix` function using `test_labels` and `predictions` as parameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "print(confusion_matrix(test_labels,predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[541 404  28]\n",
      " [203 824  34]\n",
      " [ 38 103 340]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Your Own Tweet\n",
    "\n",
    "Nice work! The confusion matrix should line up with your intuition. The classifier predicts tweets that were actually from New York as either New York tweets or London tweets, but almost never Paris tweets. Similarly, the classifier rarely misclassifies the tweets that were actually from Paris. Tweets coming from two English speaking countries are harder to distinguish than tweets in different languages.\n",
    "\n",
    "Now it's your chance to write a tweet and see how the classifier works! Create a string and store it in a variable named `tweet`. \n",
    "\n",
    "Call `counter`'s `.transform()` method using `[tweet]` as a parameter. Save the result as `tweet_counts`. Notice that your variable has to be in an array &mdash; `.transform()` can't take just a string, it must be a list. \n",
    "\n",
    "Finally, pass `tweet_counts` as parameter to `classifier`'s `.predict()` method. Print the result. This should give you the prediction for the tweet. Remember a `0` represents New York, a `1` represents London, and a `2` represents Paris. Can you write different tweets that the classifier predicts as being from New York, London, and Paris?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "tweet = 'amour'\r\n",
    "tweet_counts = counter.transform([tweet])\r\n",
    "print(classifier.predict(tweet_counts))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "b3b63422298489e73a6a82189c9eec886d8dc1651fc83ba78da4262e6c4d3529"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}